Changqi Du 20508921 
Difei Zhang 20530592

a) Our domain is World War II military infomation system. It involves information about the military structure (for example the size of the various types of battle groups or units), significant figures in each country and major land engagements. To limit the scope of our information system, we only consider the armies (not including the navy or air forces) and land operations in World War II. We decide to create a new QA system as we are very interested in the history of World War II. We hope that our QA system can be deployed in some war history museum and answer questions from tourists and visitors. 

b) We used both the top-down and bottom-up approaches strategies when defining terms or classes in our ontology. We find that the driving factor for which strategy we use is usually the questions that we want to answer or information that we want to include. For example, we wanted to include specific figures like Douglas MacArthur, so we started with him as an instance and created superclasses, such as General or Commander, that subsume the idea of such individual figures. On the other hand, we sometimes find that we want to include additional information in our ontology and thus need to expand by adding subclasses. For example, we originally had only the Location class with no subclasses. However, we realized that specifying whether a location is a city or not can help us define whether an engagement taking place at that location is a siege or a battle, so we added the City and NonCity subclasses. Furthermore, we thought it might be interesting to classify cities as a MajorCity based on the population so we added that subclass as well. Thus, where we start building a class hierachy really depends on what ideas or information we first had in mind and then what ideas we wanted to include later on in the process.

In general we find that focusing on a particular branch of the class hierarchy at a time to be helpful. The benefits are even more pronounced for us because our idea for the QA system kept changing. For instance we would start from a very small part of the big picture, such as the Unit class hierachy for talking about army structure. To find the kind of information to include, we looked up some battle group infomation from the Internet. For some time, we only worried about making subclasses in this part of the hierarchy and creating object properties that relate to the same hierarchy (like consistOf). Focusing on only part of class structure makes the problem easier to handle. Later when we felt that armies should be related to the battles they fought, we started working on the Engagement part of the class hierarchy. Also, we felt a country should have famous figures, so that we can answer questions like "who is the russian legendary sniper who killed 309 soliders". Since our idea changed from just creating a simple QA system that explains the structure of modern US Army (like how many Battalions an army contains) to creating one that explains World War II armies and battles, we also benefited from having relatively isolated class hierarchies since we can easily port the Unit hierarchy to our new purpose. 

During development, we often used DL Query in protege to sanity check the reasoning in our ontology. We would look up queries like "isParticipantOf some Siege" to make sure that the relationships between armies and engagements are correct and to make sure for example that SiegeOfLeningrad is correctly labelled as a Siege (we asserted that it is an Engagement but it fits the definition of a Siege). Often we find that synchronizing the reasoner and observing the inferred properties on instances is helpful enough. For instance, we would often test if inverse functions are inferred properly by asserting for example the hasParticipant property and observing if the isParticipantOf property is correctly inferred from the other object. We didn't find the OntoGraf tool to be too useful but it was a cool tool that allows us to visualize our hard work and was a motivating factor.

In terms of difficulties encountered, one of the difficulties is that every time we try to expand our domain it's difficult for us to figure out the structure and relationship between the existing stuff and newly added stuff. I believe if we have a very clear image on what our QA system is at the very beginnning. Then there should be a more organized way for structuring. Also, we felt a bit limited by our lack of mastery of ontologies since we only knew how to define similar properties as shown in the tutorial. Sometimes we felt the need to define more complex properties such as ones that can be inferred from other properties but we did not know how to do so. Thus, thinking about what useful information our system can provide given our limited tools also became part of our process.
